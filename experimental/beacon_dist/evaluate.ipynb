{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import NamedTuple\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import string\n",
    "\n",
    "from experimental.beacon_dist import model, utils, train, generate_letter_dataset, generate_ycb_dataset\n",
    "import experimental.beacon_dist.multiview_dataset as mvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492b171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = glob.glob('/home/erick/scratch/beacon_dist/ycb_100k_scenes_4_view_strafe.part_0000[0-1].npz')\n",
    "model_path = '/home/erick/scratch/ycb_10k_strafe_test/model_000000128.pt'\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "ENVIRONMENTS_PER_BATCH = 90\n",
    "QUERIES_PER_ENVIRONMENT = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ce2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae7bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    m = model.ConfigurationModel(\n",
    "            model.ConfigurationModelParams(\n",
    "            descriptor_size=256,\n",
    "            descriptor_embedding_size=32,\n",
    "            position_encoding_factor=10000,\n",
    "            num_encoder_heads=2,\n",
    "            num_encoder_layers=2,\n",
    "            num_decoder_heads=2,\n",
    "            num_decoder_layers=2,\n",
    "        )\n",
    "    )\n",
    "    state_dict = torch.load(model_path)\n",
    "    state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "    m.load_state_dict(state_dict)\n",
    "    m.eval()\n",
    "    return m.to('cuda')\n",
    "\n",
    "m = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eval_dataset(dataset_paths):\n",
    "    return mvd.MultiviewDataset(mvd.DatasetInputs(file_paths=dataset_paths, index_path=None, data_tables=None))\n",
    "    \n",
    "dataset = load_eval_dataset(eval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cd34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate(m, dataset):\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=ENVIRONMENTS_PER_BATCH,\n",
    "        collate_fn=train.make_collator_fn(QUERIES_PER_ENVIRONMENT),\n",
    "        num_workers=10,\n",
    "    )\n",
    "    \n",
    "    model_output = []\n",
    "    query_labels = []\n",
    "    context_image_ids = []\n",
    "    query_image_ids = []\n",
    "    queries = []\n",
    "    \n",
    "    # Generate queries\n",
    "    with torch.no_grad():\n",
    "        for i, (batch, query) in enumerate(tqdm.tqdm(data_loader)):\n",
    "            batch = batch.to(\"cuda\")\n",
    "            query = query.to(\"cuda\")\n",
    "        \n",
    "            model_out = torch.sigmoid(m(batch, query))\n",
    "            # Compute labels\n",
    "            labels = utils.is_valid_configuration(batch.query.class_label, query)\n",
    "            \n",
    "            model_output.append(model_out.to('cpu'))\n",
    "            query_labels.append(labels.to('cpu'))\n",
    "            context_image_ids.append(batch.context.image_id.to('cpu'))\n",
    "            query_image_ids.append(batch.query.image_id.to('cpu'))\n",
    "            queries.append(query.to('cpu'))\n",
    "            \n",
    "            \n",
    "    return (\n",
    "        model_output,\n",
    "        query_labels,\n",
    "        context_image_ids,\n",
    "        query_image_ids,\n",
    "        queries\n",
    "    )\n",
    "    \n",
    "output_list, labels_list, context_image_ids_list, query_image_ids_list, queries_list = evaluate(m, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.concatenate(output_list)\n",
    "labels = torch.concatenate(labels_list)\n",
    "context_image_ids = torch.concatenate(context_image_ids_list)\n",
    "query_image_ids = torch.concatenate(query_image_ids_list)\n",
    "# queries = torch.concatenate(queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f03d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorRates(NamedTuple):\n",
    "    threshold: float\n",
    "    true_positive: float\n",
    "    true_negative: float\n",
    "    false_positive: float\n",
    "    false_negative: float\n",
    "\n",
    "def compute_error_rates(outputs: torch.tensor, labels: torch.tensor, threshold: float):\n",
    "    thresholded_outputs = outputs > threshold\n",
    "    \n",
    "    true_positive_count = torch.sum(torch.logical_and(thresholded_outputs, labels))\n",
    "    false_positive_count = torch.sum(torch.logical_and(thresholded_outputs, np.logical_not(labels)))\n",
    "    true_negative_count = torch.sum(torch.logical_and(torch.logical_not(thresholded_outputs), torch.logical_not(labels)))\n",
    "    false_negative_count = torch.sum(torch.logical_and(torch.logical_not(thresholded_outputs), labels))\n",
    "    \n",
    "    return ErrorRates(\n",
    "        threshold=threshold,\n",
    "        true_positive=true_positive_count,\n",
    "        true_negative=true_negative_count,\n",
    "        false_positive=false_positive_count,\n",
    "        false_negative=false_negative_count\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(outputs, labels):\n",
    "    thresholds = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]\n",
    "    error_rates = [compute_error_rates(outputs, labels, threshold) for threshold in thresholds]\n",
    "    \n",
    "    xs = [er.false_positive / (er.false_positive + er.true_negative) for er in error_rates]\n",
    "    ys = [er.true_positive / (er.true_positive + er.false_negative) for er in error_rates]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(xs, ys, 'o-')\n",
    "    plt.xlabel('$FP/(FP+TN)$')\n",
    "    plt.ylabel('$TP/(TP+FN)$')\n",
    "    for x, y, label in zip(xs, ys, thresholds):\n",
    "        plt.text(x, y, label)\n",
    "    \n",
    "    plt.title('ROC Curve')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_results(output, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d78888",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f0e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = np.argmax(output - labels)\n",
    "image_id = image_ids[batch_idx].item()\n",
    "letters = image_descriptors[image_descriptors['image_id'] == image_id]\n",
    "query = queries[batch_idx]\n",
    "letter_set = {x['char']: generate_data.LetterPosition(x=x['x'], y=x['y'], angle=x['theta']) for x in letters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18dcb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = generate_data.image_from_letter_set(letter_set, width=1280, height=720)\n",
    "kps = dataset[image_id]\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.scatter(kps.x, kps.y, c=kps.class_label)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff554569",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.scatter(kps.x[query], kps.y[query], c=kps.class_label[query])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f20d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
